Homework 5
================
Jerry Chao, Uni: Jyc2171
November 16, 2020

``` r
library(tidyverse)
```

    ## ── Attaching packages ──────────────────────────────────────────────────────────────────────────────────── tidyverse 1.3.0 ──

    ## ✓ ggplot2 3.3.2     ✓ purrr   0.3.4
    ## ✓ tibble  3.0.3     ✓ dplyr   1.0.2
    ## ✓ tidyr   1.1.2     ✓ stringr 1.4.0
    ## ✓ readr   1.3.1     ✓ forcats 0.5.0

    ## ── Conflicts ─────────────────────────────────────────────────────────────────────────────────────── tidyverse_conflicts() ──
    ## x dplyr::filter() masks stats::filter()
    ## x dplyr::lag()    masks stats::lag()

``` r
library(rvest)
```

    ## Loading required package: xml2

    ## 
    ## Attaching package: 'rvest'

    ## The following object is masked from 'package:purrr':
    ## 
    ##     pluck

    ## The following object is masked from 'package:readr':
    ## 
    ##     guess_encoding

``` r
knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_color_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem 1

Read in the data.

``` r
homicide_df =
  read_csv("homicide_data/homicide-data.csv") %>%
  mutate(
    city_state = str_c(city, state, sep = "_"),
    resolved = case_when(
      disposition == "Closed without arrest" ~ "unsolved",
      disposition == "Open/No arrest"        ~ "unsolved",
      disposition == "Closed by arrest"      ~ "solved"
    )
  ) %>%
  select(city_state, resolved) %>% 
  filter(city_state != "Tulsa_AL")
```

    ## Parsed with column specification:
    ## cols(
    ##   uid = col_character(),
    ##   reported_date = col_double(),
    ##   victim_last = col_character(),
    ##   victim_first = col_character(),
    ##   victim_race = col_character(),
    ##   victim_age = col_character(),
    ##   victim_sex = col_character(),
    ##   city = col_character(),
    ##   state = col_character(),
    ##   lat = col_double(),
    ##   lon = col_double(),
    ##   disposition = col_character()
    ## )

Let’s look at this a bit

``` r
aggregate_df =
  homicide_df %>% 
  group_by(city_state) %>% 
  summarize(
    hom_total = n(),
    hom_unsolved = sum(resolved == "unsolved")
  )
```

    ## `summarise()` ungrouping output (override with `.groups` argument)

``` r
homicide_df %>% 
  group_by(city_state) %>% 
  summarize(
    hom_total = n()
  ) %>% 
  arrange(hom_total)
```

    ## `summarise()` ungrouping output (override with `.groups` argument)

    ## # A tibble: 50 x 2
    ##    city_state        hom_total
    ##    <chr>                 <int>
    ##  1 Tampa_FL                208
    ##  2 Savannah_GA             246
    ##  3 San Bernardino_CA       275
    ##  4 Durham_NC               276
    ##  5 Denver_CO               312
    ##  6 Minneapolis_MN          366
    ##  7 Sacramento_CA           376
    ##  8 Albuquerque_NM          378
    ##  9 Long Beach_CA           378
    ## 10 Omaha_NE                409
    ## # … with 40 more rows

Can I do a prop test for a single city?

``` r
prop.test(
  aggregate_df %>%  filter(city_state == "Baltimore_MD") %>%  pull(hom_unsolved),
  aggregate_df %>%  filter(city_state == "Baltimore_MD") %>%  pull(hom_total))
```

    ## 
    ##  1-sample proportions test with continuity correction
    ## 
    ## data:  aggregate_df %>% filter(city_state == "Baltimore_MD") %>% pull(hom_unsolved) out of aggregate_df %>% filter(city_state == "Baltimore_MD") %>% pull(hom_total), null probability 0.5
    ## X-squared = 239.01, df = 1, p-value < 2.2e-16
    ## alternative hypothesis: true p is not equal to 0.5
    ## 95 percent confidence interval:
    ##  0.6275625 0.6631599
    ## sample estimates:
    ##         p 
    ## 0.6455607

So can repeat this for each city\_state - this is an iteration issue The
input is city\_state

``` r
prop.test(
  aggregate_df %>%  filter(city_state == "Baltimore_MD") %>%  pull(hom_unsolved),
  aggregate_df %>%  filter(city_state == "Baltimore_MD") %>%  pull(hom_total)) %>% 
  broom::tidy()
```

    ## # A tibble: 1 x 8
    ##   estimate statistic  p.value parameter conf.low conf.high method    alternative
    ##      <dbl>     <dbl>    <dbl>     <int>    <dbl>     <dbl> <chr>     <chr>      
    ## 1    0.646      239. 6.46e-54         1    0.628     0.663 1-sample… two.sided

Try to iterate ……… Try to create a fourth column that has the data that
is requested in homework assignment

``` r
#conceptually, this is the framework:
#aggregate_df %>% 
#  mutate(
#    prop_tests = map( ....... )
#  )

results_df =
aggregate_df %>% 
  mutate(
    prop_tests = map2(.x = hom_unsolved, .y = hom_total, ~prop.test(x = .x, n = .y)),
    tidy_tests = map(.x = prop_tests, ~broom::tidy(.x))
  ) %>% 
  select(-prop_tests) %>% 
  unnest(tidy_tests) %>% 
  select(city_state, estimate, conf.low, conf.high)
```

``` r
results_df %>%
  mutate(
    city_state = fct_reorder(city_state, estimate)  
  ) %>%
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) +
  theme(legend.position = "bottom", axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```

<img src="p8105_hw_jyc2171_files/figure-gfm/unnamed-chunk-6-1.png" width="90%" />

``` r
# this is an alternate way to approach
# city_prop_tst = function(df) {
  
#  n_unsolved ...
#  n_total ...

#  prop.test(........)  
  
#}

homicide_df =
  read_csv("homicide_data/homicide-data.csv") %>%
  mutate(
    city_state = str_c(city, state, sep = "_"),
    resolved = case_when(
      disposition == "Closed without arrest" ~ "unsolved",
      disposition == "Open/No arrest"        ~ "unsolved",
      disposition == "Closed by arrest"      ~ "solved"
    )
  ) %>%
  select(city_state, resolved) %>% 
  filter(city_state != "Tulsa_AL") %>% 
  nest(data = resolved)
```

    ## Parsed with column specification:
    ## cols(
    ##   uid = col_character(),
    ##   reported_date = col_double(),
    ##   victim_last = col_character(),
    ##   victim_first = col_character(),
    ##   victim_race = col_character(),
    ##   victim_age = col_character(),
    ##   victim_sex = col_character(),
    ##   city = col_character(),
    ##   state = col_character(),
    ##   lat = col_double(),
    ##   lon = col_double(),
    ##   disposition = col_character()
    ## )

## Problem 2 ideas …

import one dataset

``` r
data_1 = read_csv("lda_data/con_01.csv")
```

    ## Parsed with column specification:
    ## cols(
    ##   week_1 = col_double(),
    ##   week_2 = col_double(),
    ##   week_3 = col_double(),
    ##   week_4 = col_double(),
    ##   week_5 = col_double(),
    ##   week_6 = col_double(),
    ##   week_7 = col_double(),
    ##   week_8 = col_double()
    ## )

but the challenge is how to do it across the 10 subjects in the
experimental group and 10 subjects in control group?

start with a dataframe with the names of all of your names

``` r
#Live session lecture notes - please ignore
## if you can do this, then you would solve this part of the homework assignment
## then after this, you can do some mutate stuff
## probably need to pivot to made the dataset tidy
## could I get the actual dataframe I wanted to have to do some analysis or some plots
## this is a data organizational problem and data tidying problem
## in the end, everything will be in one dataframe
##list.files()
##list.files("lda_data")

#First, my function to read in all 20 .csv files

########################
# read_all_csvs = function(x) {
#   
#   data = read_csv(x)
#  
#   tibble(
#     data = data
#   )
#   
# }
# 
# path_df =
#   tibble(
#     files = list.files("lda_data"),
#     path = str_c("lda_data/", files)
#   ) %>% 
#   mutate(
#     data = map(path, read_all_csvs, col_types = "dddddddd")
#   ) %>% 
#   unnest()
#   
# path_df =
# path_df %>% 
#   mutate(
#     data = map(path, read_all_csvs, col_types = "dddddddd")
#   ) %>% 
#   unnest()
#################################


#####
study_data = 
  tibble(
    files = list.files("lda_data"),
    path = str_c("lda_data/", files)
  ) %>% 
  mutate(data = map(path, read_csv, col_types = "dddddddd")) %>% 
  unnest() %>% 
  pivot_longer(
    week_1:week_8,
    names_to = "week",
    values_to = "repeated_measure"
  ) %>% 
  select(-path) %>% 
  rename(
    arm_id = files
  ) %>%
  separate(arm_id, into = c("arm_id", ".csv"), sep = 6) %>% 
  select(-.csv)
```

    ## Warning: `cols` is now required when using unnest().
    ## Please use `cols = c(data)`

``` r
######

# #Next, my for loop
# output = vector("list", length = 20)
# 
# for (i in 1:20) {
#   
#   output[[i]] = read_all_csvs(path_df$path[[i]])
# 
# }
# 
# study_data =
#   path_df %>% 
#   separate(path, into = c("prefix", "arm_id"), sep = 9) %>% 
#   select(-prefix) %>% 
#   separate(arm_id, into = c("arm_id", "csv"), sep = 6) %>%
#   select(-csv) %>%
#   unnest(data) %>%
#   mutate(
#     week_1 = data$week_1,
#     week_2 = data$week_2,
#     week_3 = data$week_3,
#     week_4 = data$week_4,
#     week_5 = data$week_5,
#     week_6 = data$week_6,
#     week_7 = data$week_7,
#     week_8 = data$week_8,
#   ) %>%   
#   select(arm_id, week_1:week_8) %>% 
#   pivot_longer(
#     data$week_1:data$week_8,
#     names_to = "week",
#     values_to = "repeated_measure"
#   )
#   
#   
#   
#   
# #read_csv(path_df$path[[1]])
# #read_csv(path_df$path[[2]])
# 
```

``` r
#Spaghetti plot
study_data %>% 
  ggplot(aes(x = week, y = repeated_measure)) +
  geom_point(aes(color = arm_id)) +
  geom_line(aes(group = arm_id, color = arm_id))
```

<img src="p8105_hw_jyc2171_files/figure-gfm/unnamed-chunk-10-1.png" width="90%" />

The spaghetti plot shows that in general, subjects in the experimental
arm (denoted by warm colors) generally have higher values of the
repeated measure compared to subjects in the control arm. In addition,
the values of the repeated measure trends upwards over time (that is,
the value of the repeated measure increased weekly).

# Problem 3

``` r
#First, I will create the function using the specified given data:

t_test = function(samp_size = 30, mu = 0, sigma = 5) {
  
  sim_data =
    tibble(
      x = rnorm(n = samp_size, mean = mu, sd = sigma)
    )

  test = t.test(x ~ 1, data = sim_data)
  
  broom::tidy(test)
  
}

#########
# sim_t_test = function(n_samp = 30, mu = 2, sigma = 5) {
# 
#    sim_data = tibble(
#      x = rnorm(n_samp, mean = mu, sd = sigma)
#    )
# 
#    test = t.test(x ~ 1, data = sim_data)
# 
#    broom::tidy(test)
# 
#  }
# 
#  sim_results =
#    tibble(mu = 0:6) %>%
#    mutate(
#      output_lists = map(.x = mu, ~rerun(100, sim_t_test(mu = .x))),
#      estimate_dfs = map(output_lists, bind_rows)
#    ) %>%
#    select(-output_lists)

####
##for loop approach
# plot_data = c()
# for (i in 0:6) {
#   plot_data[[i+1]] =
#     tibble(mu = i) %>%
#     mutate(raw = map(.x = mu, ~ rerun(5000, rnorm(30, .x, 5)))) %>%
#     unnest(raw) %>%
#     mutate(
#       t_test = map(.x = raw, ~ t.test(.x, mu =0, sd = 5)),
#       t_test = map(t_test, broom::tidy)
#     ) %>%
#     unnest(t_test) %>%
#     mutate(t_accept_h0 = p.value > 0.05)
# }
# plot_data = plot_data %>% bind_rows()
###
```

``` r
#first doing 100 simulations, will expand to 5000 later after I get the code correct



sim_results = 
  tibble(mu = 0:6) %>% 
  mutate(
    output_lists = map(.x = mu, ~rerun(100, t_test(mu = .x))),
    estimate_dfs = map(output_lists, bind_rows)
  ) %>% 
  select(-output_lists) %>% 
  unnest(estimate_dfs) %>% 
  select(mu, estimate, p.value)


# n_list =
#   list(
#     "mu = 0" = 1,
#     "mu = 1" = 2,
#     "mu = 2" = 3,
#     "mu = 3" = 4,
#     "mu = 4" = 5,
#     "mu = 5" = 6,
#     "mu = 6" = 7
#   )

# output = vector("list", length = 7)
# 
# for (i in 1:7) {
#   
#   output[[i]] = rerun(10, t_test(mu = n_list[[i]])) %>% 
#     bind_rows()
#   
# }

# sim_results = 
#   tibble(
#     mu = c(1, 2, 3, 4, 5, 6, 7)
#   ) %>% 
#   mutate(
#     output_lists = map(.x = mu, ~ rerun(30, t_test(.x)))  ),
#     estimates_p_val = map(output_lists, bind_rows)
#   )  
#       
#       estimate_df = map(output_lists, bind_rows)
#     ) %>% 
#     select(-output_lists) %>% 
```

``` r
#Full 5000 simulations per mu level

sim_results = 
  tibble(mu = 0:6) %>% 
  mutate(
    output_lists = map(.x = mu, ~rerun(5000, t_test(mu = .x))),
    estimate_dfs = map(output_lists, bind_rows)
  ) %>% 
  select(-output_lists) %>% 
  unnest(estimate_dfs) %>% 
  select(mu, estimate, p.value)

#Plot of proportion of times the null was rejected.  I am interpreting this to mean the proportion of p values < 0.05

significance_df =
sim_results %>% 
  mutate(
    stat_sig = case_when(
      p.value > 0.05 ~ "not significant",
      p.value < 0.05 ~ "significant"
    )
  )

prop_sig =
significance_df %>% 
  group_by(mu) %>%
  summarize(
    mu_total = n(),
    mu_sig = sum(stat_sig == "significant")
  )
```

    ## `summarise()` ungrouping output (override with `.groups` argument)

``` r
#Plot of true value of mu on x axis and proportion of statistically significant p values on y axis:
prop_sig %>% 
  ggplot(aes(x = mu, y = mu_sig, color = mu)) +
  geom_point() +
  geom_line()
```

<img src="p8105_hw_jyc2171_files/figure-gfm/unnamed-chunk-14-1.png" width="90%" />

``` r
#Plot of estimates on y axis and true value of mu on x axis
sim_results %>% 
  ggplot(aes(x = mu, y = estimate, group = mu, color = mu)) +
  geom_point(alpha = 0.4) +
  geom_boxplot()
```

<img src="p8105_hw_jyc2171_files/figure-gfm/unnamed-chunk-14-2.png" width="90%" />

``` r
#Plot of estimates on y axis for statistically significant p values and mu on x axis
significance_df %>%
  filter(
    stat_sig == "significant"
  ) %>% 
  ggplot(aes(x = mu,  y = estimate, group = mu, color = mu)) +
  geom_point(alpha = 0.2) +
  geom_boxplot()
```

<img src="p8105_hw_jyc2171_files/figure-gfm/unnamed-chunk-14-3.png" width="90%" />

``` r
# first, I will only do the simulation with a small number of cycles, 5.  I will increase to 5000 later, after I have figured out the code
# sim_power_0 = 
#   rerun(5, sim_power(mu = 0)) %>% 
#   bind_rows() %>% 
#   select(estimate, p.value)
# 
# sim_power_1 =
#   rerun(5, sim_power(mu = 1)) %>% 
#   bind_rows() %>% 
#   select(estimate, p.value)
# 
# sim_power_2 =
#   rerun(5, sim_power(mu = 2)) %>% 
#   bind_rows() %>% 
#   select(estimate, p.value)
# 
# sim_power_3 =
#   rerun(5, sim_power(mu = 3)) %>% 
#   bind_rows() %>% 
#   select(estimate, p.value)
# 
# sim_power_4 =
#   rerun(5, sim_power(mu = 4)) %>% 
#   bind_rows() %>% 
#   select(estimate, p.value)
# 
# sim_power_5 =
#   rerun(5, sim_power(mu = 5)) %>% 
#   bind_rows() %>% 
#   select(estimate, p.value)
# 
# sim_power_6 =
#   rerun(5, sim_power(mu = 6)) %>% 
#   bind_rows() %>% 
#   select(estimate, p.value)
# 
```
