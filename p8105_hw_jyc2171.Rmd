---
title: "Homework 5"
author: "Jerry Chao, Uni: Jyc2171"
date: "November 16, 2020"
output: github_document
---

```{r setup}
library(tidyverse)
library(rvest)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_color_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem 1

Read in the data.

```{r}
homicide_df =
  read_csv("homicide_data/homicide-data.csv") %>%
  mutate(
    city_state = str_c(city, state, sep = "_"),
    resolved = case_when(
      disposition == "Closed without arrest" ~ "unsolved",
      disposition == "Open/No arrest"        ~ "unsolved",
      disposition == "Closed by arrest"      ~ "solved"
    )
  ) %>%
  select(city_state, resolved) %>% 
  filter(city_state != "Tulsa_AL")
  

```


Let's look at this a bit

```{r}
aggregate_df =
  homicide_df %>% 
  group_by(city_state) %>% 
  summarize(
    hom_total = n(),
    hom_unsolved = sum(resolved == "unsolved")
  )

homicide_df %>% 
  group_by(city_state) %>% 
  summarize(
    hom_total = n()
  ) %>% 
  arrange(hom_total)
```

Can I do a prop test for a single city?

```{r}
prop.test(
  aggregate_df %>%  filter(city_state == "Baltimore_MD") %>%  pull(hom_unsolved),
  aggregate_df %>%  filter(city_state == "Baltimore_MD") %>%  pull(hom_total))
```

So can repeat this for each city_state - this is an iteration issue
The input is city_state

```{r}
prop.test(
  aggregate_df %>%  filter(city_state == "Baltimore_MD") %>%  pull(hom_unsolved),
  aggregate_df %>%  filter(city_state == "Baltimore_MD") %>%  pull(hom_total)) %>% 
  broom::tidy()
```

Try t0 iterate .........
Try to create a fourth column that has the data that is requested in homework assignment

```{r}
#conceptually, this is the framework:
#aggregate_df %>% 
#  mutate(
#    prop_tests = map( ....... )
#  )

results_df =
aggregate_df %>% 
  mutate(
    prop_tests = map2(.x = hom_unsolved, .y = hom_total, ~prop.test(x = .x, n = .y)),
    tidy_tests = map(.x = prop_tests, ~broom::tidy(.x))
  ) %>% 
  select(-prop_tests) %>% 
  unnest(tidy_tests) %>% 
  select(city_state, estimate, conf.low, conf.high)
```

```{r}
results_df %>%
  mutate(
    city_state = fct_reorder(city_state, estimate)  
  ) %>%
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) +
  theme(legend.position = "bottom", axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))


```



```{r, error = TRUE}
# this is an alternate way to approach
# city_prop_tst = function(df) {
  
#  n_unsolved ...
#  n_total ...

#  prop.test(........)  
  
#}

homicide_df =
  read_csv("homicide_data/homicide-data.csv") %>%
  mutate(
    city_state = str_c(city, state, sep = "_"),
    resolved = case_when(
      disposition == "Closed without arrest" ~ "unsolved",
      disposition == "Open/No arrest"        ~ "unsolved",
      disposition == "Closed by arrest"      ~ "solved"
    )
  ) %>%
  select(city_state, resolved) %>% 
  filter(city_state != "Tulsa_AL") %>% 
  nest(data = resolved)
```

## Problem 2 ideas ...

import one dataset

```{r}
data_1 = read_csv("lda_data/con_01.csv")
```

but the challenge is how to do it across the 10 subjects in the experimental group and 10 subjects in control group?

start with a dataframe with the names of all of your names

```{r}
#Live session lecture notes - please ignore
## if you can do this, then you would solve this part of the homework assignment
## then after this, you can do some mutate stuff
## probably need to pivot to made the dataset tidy
## could I get the actual dataframe I wanted to have to do some analysis or some plots
## this is a data organizational problem and data tidying problem
## in the end, everything will be in one dataframe
##list.files()
##list.files("lda_data")

#First, my function to read in all 20 .csv files
read_all_csvs = function(x) {
  
  data = read_csv(x)
 
  tibble(
    data = data
  )
  
}

path_df =
  tibble(
    path = list.files("lda_data"),
  ) %>% 
  mutate(
    path = str_c("lda_data/", path)
  )

path_df =
path_df %>% 
  mutate(
    data = map(path, read_all_csvs)
  )

#Next, my for loop
output = vector("list", length = 20)

for (i in 1:20) {
  
  output[[i]] = read_all_csvs(path_df$path[[i]])

}

study_data =
  path_df %>% 
  separate(path, into = c("prefix", "arm_id"), sep = 9) %>% 
  select(-prefix) %>% 
  separate(arm_id, into = c("arm_id", "csv"), sep = 6) %>%
  select(-csv) %>%
  unnest(data) %>%
  mutate(
    week_1 = data$week_1,
    week_2 = data$week_2,
    week_3 = data$week_3,
    week_4 = data$week_4,
    week_5 = data$week_5,
    week_6 = data$week_6,
    week_7 = data$week_7,
    week_8 = data$week_8,
  ) %>% 
  select(arm_id, week_1:week_8) %>% 
  pivot_longer(
    week_1:week_8,
    names_to = "week",
    values_to = "repeated_measure"
  )
  
#read_csv(path_df$path[[1]])
#read_csv(path_df$path[[2]])


```

```{r}
#Spaghetti plot
study_data %>% 
  ggplot(aes(x = week, y = repeated_measure)) +
  geom_point(aes(color = arm_id)) +
  geom_line(aes(group = arm_id, color = arm_id))
```

The spaghetti plot shows that in general, subjects in the experimental arm (denoted by warm colors) generally have higher values of the repeated measure compared to subjects in the control arm.  In addition, the values of the repeated measure trends upwards over time (that is, the value of the repeated measure increased weekly).

# Problem 3 

```{r, echo = FALSE}
##Pleaes ignore these lecture notes written down from synchronous class session
#This is a problem about simulations
#given: sample size = 30
#given: sd = 5
#change: means.  means of 1, 2, 3, 4, 5, 6
#for each mean, generate 5000 datasets
#not exporting means, sds
#export the results of the hypothesis test, whether the mean is equal to zero.
#when mean = 0, reject or fail to reject the null hypthesis a certain percentage of times - see what happens as you move from the means.
#make two plots - estimated plot when true mean = zero
#and then filter, show only when p values<0.05 and then compute the mean, what would that mean look like.
# you are always testing that mean = 0

```

```{r}
#First, I will create the function using the specified given data:

sim_power = function(samp_size = 30, mu = 0, sigma = 5) {
  
  sim_data =
    tibble(
      x = rnorm(n = samp_size, mean = mu, sd = sigma)
  )

  sim_data %>% 
    t.test() %>% 
    broom::tidy()
  
}


```

```{r}
output = vector("list", length = 5000)

for (i in 1:5000) {
  
  output[[i]] = sim_power(mu = 0)

}

bind_rows(output)
```

```{r}
n_list =
  list(
    "mu = 0" = 0,
    "mu = 1" = 1,
    "mu = 2" = 2,
    "mu = 3" = 3,
    "mu = 4" = 4,
    "mu = 5" = 5,
    "mu = 6" = 6
  )

for (i in 1:6) {
  
  output[[i]] =
    rerun(100, sim_power(mu = n_list[[i]])) %>% 
    bind_rows()
  
}

sim_results = 
  tibble(
    mu = c(0, 1, 2, 3, 4, 5, 6)
  ) %>% 
    mutate(
      output_lists = map(.x = mu, ~ rerun(5, sim_power(.x)))
      
    )  
      ,
      estimate_df = map(output_lists, bind_rows)
    ) %>% 
    select(-output_lists) %>% 
    unnest(estimate_df)
```


```{r}
# first, I will only do the simulation with a small number of cycles, 5.  I will increase to 5000 later, after I have figured out the code
sim_power_0 = 
  rerun(5, sim_power(mu = 0)) %>% 
  bind_rows() %>% 
  select(estimate, p.value)

sim_power_1 =
  rerun(5, sim_power(mu = 1)) %>% 
  bind_rows() %>% 
  select(estimate, p.value)

sim_power_2 =
  rerun(5, sim_power(mu = 2)) %>% 
  bind_rows() %>% 
  select(estimate, p.value)

sim_power_3 =
  rerun(5, sim_power(mu = 3)) %>% 
  bind_rows() %>% 
  select(estimate, p.value)

sim_power_4 =
  rerun(5, sim_power(mu = 4)) %>% 
  bind_rows() %>% 
  select(estimate, p.value)

sim_power_5 =
  rerun(5, sim_power(mu = 5)) %>% 
  bind_rows() %>% 
  select(estimate, p.value)

sim_power_6 =
  rerun(5, sim_power(mu = 6)) %>% 
  bind_rows() %>% 
  select(estimate, p.value)


```

