---
title: "Homework 5"
author: "Jerry Chao, Uni: Jyc2171"
date: "November 16, 2020"
output: github_document
---

```{r setup, echo = FALSE}
library(tidyverse)
library(rvest)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_color_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem 1

Read in the data.

```{r}
homicide_df =
  read_csv("homicide_data/homicide-data.csv") %>%
  mutate(
    city_state = str_c(city, state, sep = "_"),
    resolved = case_when(
      disposition == "Closed without arrest" ~ "unsolved",
      disposition == "Open/No arrest"        ~ "unsolved",
      disposition == "Closed by arrest"      ~ "solved"
    )
  ) %>%
  select(city_state, resolved) %>% 
  filter(city_state != "Tulsa_AL")
```


Let's look at this a bit

```{r}
aggregate_df =
  homicide_df %>% 
  group_by(city_state) %>% 
  summarize(
    hom_total = n(),
    hom_unsolved = sum(resolved == "unsolved")
  )

homicide_df %>% 
  group_by(city_state) %>% 
  summarize(
    hom_total = n()
  ) %>% 
  arrange(hom_total)
```

Can I do a prop test for a single city?

```{r}
prop.test(
  aggregate_df %>%  filter(city_state == "Baltimore_MD") %>%  pull(hom_unsolved),
  aggregate_df %>%  filter(city_state == "Baltimore_MD") %>%  pull(hom_total))
```

So can repeat this for each city_state - this is an iteration issue
The input is city_state

```{r}
prop.test(
  aggregate_df %>%  filter(city_state == "Baltimore_MD") %>%  pull(hom_unsolved),
  aggregate_df %>%  filter(city_state == "Baltimore_MD") %>%  pull(hom_total)) %>% 
  broom::tidy()
```

Try to iterate .........
Try to create a fourth column that has the data that is requested in homework assignment

```{r}
#conceptually, this is the framework:
#aggregate_df %>% 
#  mutate(
#    prop_tests = map( ....... )
#  )

results_df =
aggregate_df %>% 
  mutate(
    prop_tests = map2(.x = hom_unsolved, .y = hom_total, ~prop.test(x = .x, n = .y)),
    tidy_tests = map(.x = prop_tests, ~broom::tidy(.x))
  ) %>% 
  select(-prop_tests) %>% 
  unnest(tidy_tests) %>% 
  select(city_state, estimate, conf.low, conf.high)
```

```{r}
results_df %>%
  mutate(
    city_state = fct_reorder(city_state, estimate)  
  ) %>%
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) +
  theme(legend.position = "bottom", axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```


```{r, error = TRUE}
# this is an alternate way to approach
# city_prop_tst = function(df) {
  
#  n_unsolved ...
#  n_total ...

#  prop.test(........)  
  
#}

homicide_df =
  read_csv("homicide_data/homicide-data.csv") %>%
  mutate(
    city_state = str_c(city, state, sep = "_"),
    resolved = case_when(
      disposition == "Closed without arrest" ~ "unsolved",
      disposition == "Open/No arrest"        ~ "unsolved",
      disposition == "Closed by arrest"      ~ "solved"
    )
  ) %>%
  select(city_state, resolved) %>% 
  filter(city_state != "Tulsa_AL") %>% 
  nest(data = resolved)
```

## Problem 2

```{r, echo = FALSE}
#Live session lecture notes and exploratroy code - please ignore

#import one dataset
#data_1 = read_csv("lda_data/con_01.csv")
#but the challenge is how to do it across the 10 subjects in the experimental group and 10 subjects in control group?
#start with a dataframe with the names of all of your names

## if you can do this, then you would solve this part of the homework assignment
## then after this, you can do some mutate stuff
## probably need to pivot to made the dataset tidy
## could I get the actual dataframe I wanted to have to do some analysis or some plots
## this is a data organizational problem and data tidying problem
## in the end, everything will be in one dataframe
##list.files()
##list.files("lda_data")

#First, my function to read in all 20 .csv files

########################
# read_all_csvs = function(x) {
#   
#   data = read_csv(x)
#  
#   tibble(
#     data = data
#   )
#   
# }
# 
# path_df =
#   tibble(
#     files = list.files("lda_data"),
#     path = str_c("lda_data/", files)
#   ) %>% 
#   mutate(
#     data = map(path, read_all_csvs, col_types = "dddddddd")
#   ) %>% 
#   unnest()
#   
# path_df =
# path_df %>% 
#   mutate(
#     data = map(path, read_all_csvs, col_types = "dddddddd")
#   ) %>% 
#   unnest()
#################################
######

# #Next, my for loop
# output = vector("list", length = 20)
# 
# for (i in 1:20) {
#   
#   output[[i]] = read_all_csvs(path_df$path[[i]])
# 
# }
# 
# study_data =
#   path_df %>% 
#   separate(path, into = c("prefix", "arm_id"), sep = 9) %>% 
#   select(-prefix) %>% 
#   separate(arm_id, into = c("arm_id", "csv"), sep = 6) %>%
#   select(-csv) %>%
#   unnest(data) %>%
#   mutate(
#     week_1 = data$week_1,
#     week_2 = data$week_2,
#     week_3 = data$week_3,
#     week_4 = data$week_4,
#     week_5 = data$week_5,
#     week_6 = data$week_6,
#     week_7 = data$week_7,
#     week_8 = data$week_8,
#   ) %>%   
#   select(arm_id, week_1:week_8) %>% 
#   pivot_longer(
#     data$week_1:data$week_8,
#     names_to = "week",
#     values_to = "repeated_measure"
#   )
#   
#   
#   
#   
# #read_csv(path_df$path[[1]])
# #read_csv(path_df$path[[2]])
# 

```

```{r}
study_data = 
  tibble(
    files = list.files("lda_data"),
    path = str_c("lda_data/", files)
  ) %>% 
  mutate(data = map(path, read_csv, col_types = "dddddddd")) %>% 
  unnest() %>% 
  pivot_longer(
    week_1:week_8,
    names_to = "week",
    values_to = "repeated_measure"
  ) %>% 
  select(-path) %>% 
  rename(
    arm_id = files
  ) %>%
  separate(arm_id, into = c("arm_id", ".csv"), sep = 6) %>% 
  select(-.csv)
```

```{r}
#Spaghetti plot
study_data %>% 
  ggplot(aes(x = week, y = repeated_measure)) +
  geom_point(aes(color = arm_id)) +
  geom_line(aes(group = arm_id, color = arm_id))
```

The spaghetti plot shows that in general, subjects in the experimental arm (denoted by warm colors) generally have higher values of the repeated measure compared to subjects in the control arm.  In addition, the values of the repeated measure trends upwards over time in the experimental arm (that is, the value of the repeated measure increases weekly), more so than in the control arm.

# Problem 3 

```{r, echo = FALSE}
##Pleaes ignore these lecture notes written down from synchronous class session, and exploratory code
#This is a problem about simulations
#given: sample size = 30
#given: sd = 5
#change: means.  means of 1, 2, 3, 4, 5, 6
#for each mean, generate 5000 datasets
#not exporting means, sds
#export the results of the hypothesis test, whether the mean is equal to zero.
#when mean = 0, reject or fail to reject the null hypthesis a certain percentage of times - see what happens as you move from the means.
#make two plots - estimated plot when true mean = zero
#and then filter, show only when p values<0.05 and then compute the mean, what would that mean look like.
# you are always testing that mean = 0
# first, I will only do the simulation with a small number of cycles, 5.  I will increase to 5000 later, after I have figured out the code
# sim_power_0 = 
#   rerun(5, sim_power(mu = 0)) %>% 
#   bind_rows() %>% 
#   select(estimate, p.value)
# 
# sim_power_1 =
#   rerun(5, sim_power(mu = 1)) %>% 
#   bind_rows() %>% 
#   select(estimate, p.value)
# 
# sim_power_2 =
#   rerun(5, sim_power(mu = 2)) %>% 
#   bind_rows() %>% 
#   select(estimate, p.value)
# 
# sim_power_3 =
#   rerun(5, sim_power(mu = 3)) %>% 
#   bind_rows() %>% 
#   select(estimate, p.value)
# 
# sim_power_4 =
#   rerun(5, sim_power(mu = 4)) %>% 
#   bind_rows() %>% 
#   select(estimate, p.value)
# 
# sim_power_5 =
#   rerun(5, sim_power(mu = 5)) %>% 
#   bind_rows() %>% 
#   select(estimate, p.value)
# 
# sim_power_6 =
#   rerun(5, sim_power(mu = 6)) %>% 
#   bind_rows() %>% 
#   select(estimate, p.value)
# 
```

```{r}
#First, I will create the function using the specified given data:

t_test = function(samp_size = 30, mu = 0, sigma = 5) {
  
  sim_data =
    tibble(
      x = rnorm(n = samp_size, mean = mu, sd = sigma)
    )

  test = t.test(x ~ 1, data = sim_data)
  
  broom::tidy(test)
  
}

####
##for loop approach?
# plot_data = c()
# for (i in 0:6) {
#   plot_data[[i+1]] =
#     tibble(mu = i) %>%
#     mutate(raw = map(.x = mu, ~ rerun(5000, rnorm(30, .x, 5)))) %>%
#     unnest(raw) %>%
#     mutate(
#       t_test = map(.x = raw, ~ t.test(.x, mu =0, sd = 5)),
#       t_test = map(t_test, broom::tidy)
#     ) %>%
#     unnest(t_test) %>%
#     mutate(t_accept_h0 = p.value > 0.05)
# }
# plot_data = plot_data %>% bind_rows()
####
```


```{r}
#first doing 100 simulations, will expand to 5000 later after I get the code correct

sim_results = 
  tibble(mu = 0:6) %>% 
  mutate(
    output_lists = map(.x = mu, ~rerun(100, t_test(mu = .x))),
    estimate_dfs = map(output_lists, bind_rows)
  ) %>% 
  select(-output_lists) %>% 
  unnest(estimate_dfs) %>% 
  select(mu, estimate, p.value)


# n_list =
#   list(
#     "mu = 0" = 1,
#     "mu = 1" = 2,
#     "mu = 2" = 3,
#     "mu = 3" = 4,
#     "mu = 4" = 5,
#     "mu = 5" = 6,
#     "mu = 6" = 7
#   )

# output = vector("list", length = 7)
# 
# for (i in 1:7) {
#   
#   output[[i]] = rerun(10, t_test(mu = n_list[[i]])) %>% 
#     bind_rows()
#   
# }

# sim_results = 
#   tibble(
#     mu = c(1, 2, 3, 4, 5, 6, 7)
#   ) %>% 
#   mutate(
#     output_lists = map(.x = mu, ~ rerun(30, t_test(.x)))  ),
#     estimates_p_val = map(output_lists, bind_rows)
#   )  
#       
#       estimate_df = map(output_lists, bind_rows)
#     ) %>% 
#     select(-output_lists) %>% 
```

```{r}
#Full 5000 simulations per mu level

sim_results = 
  tibble(mu = 0:6) %>% 
  mutate(
    output_lists = map(.x = mu, ~rerun(5000, t_test(mu = .x))),
    estimate_dfs = map(output_lists, bind_rows)
  ) %>% 
  select(-output_lists) %>% 
  unnest(estimate_dfs) %>% 
  select(mu, estimate, p.value)

#Plot of proportion of times the null was rejected.  I am interpreting this to mean the proportion of p values < 0.05

significance_df =
sim_results %>% 
  mutate(
    stat_sig = case_when(
      p.value > 0.05 ~ "not significant",
      p.value < 0.05 ~ "significant"
    )
  )

prop_sig =
significance_df %>% 
  group_by(mu) %>%
  summarize(
    mu_total = n(),
    mu_sig = sum(stat_sig == "significant")
  )

#Plot of true value of mu on x axis and proportion of statistically significant p values on y axis:
prop_sig %>% 
  ggplot(aes(x = mu, y = mu_sig, color = mu)) +
  geom_point() +
  geom_line()
         
#Plot of estimates on y axis and true value of mu on x axis
sim_results %>% 
  ggplot(aes(x = mu, y = estimate, group = mu, color = mu)) +
  geom_boxplot()

#Plot of estimates on y axis for statistically significant p values and mu on x axis
significance_df %>%
  filter(
    stat_sig == "significant"
  ) %>% 
  ggplot(aes(x = mu,  y = estimate, group = mu, color = mu)) +
  geom_boxplot()
```

As mu (or the effect size) increases, the proportion of statistically significant p values < 0.05, and by convention, the proportion of times the null hypothesis is rejected (the power of the test) increases, approaching near 100% at a mu of 4.

When including all values of estimated mu's (aka mu "hat") without accounting for statistical significance, estimates of mu from a sample of 5000 are approximately equal to the true value of mu.

When including only values of estimated mu's (mu "hats") that are statistically significant (p value < 0.05), estimates of mu from a sample of 5000 are higher than the true value of mu, but only for true mu values of 1, 2, and 3.  This difference seems to disappear at mu's of >4, because at those effect sizes, the majority of p values are statistically significant.  For an effect size of zero (mu = 0), the average estimated mu has a median value that seems to be less than the true mu, but with a wide interquartile range.

