---
title: "Homework 5"
author: "Jerry Chao, Uni: Jyc2171"
date: "November 16, 2020"
output: github_document
---

```{r setup}
library(tidyverse)
library(rvest)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_color_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem 1

Read in the data.

```{r}
homicide_df =
  read_csv("homicide_data/homicide-data.csv") %>%
  mutate(
    city_state = str_c(city, state, sep = "_"),
    resolved = case_when(
      disposition == "Closed without arrest" ~ "unsolved",
      disposition == "Open/No arrest"        ~ "unsolved",
      disposition == "Closed by arrest"      ~ "solved"
    )
  ) %>%
  select(city_state, resolved) %>% 
  filter(city_state != "Tulsa_AL")
  

```


Let's look at this a bit

```{r}
aggregate_df =
  homicide_df %>% 
  group_by(city_state) %>% 
  summarize(
    hom_total = n(),
    hom_unsolved = sum(resolved == "unsolved")
  )

homicide_df %>% 
  group_by(city_state) %>% 
  summarize(
    hom_total = n()
  ) %>% 
  arrange(hom_total)
```

Can I do a prop test for a single city?

```{r}
prop.test(
  aggregate_df %>%  filter(city_state == "Baltimore_MD") %>%  pull(hom_unsolved),
  aggregate_df %>%  filter(city_state == "Baltimore_MD") %>%  pull(hom_total))
```

So can repeat this for each city_state - this is an iteration issue
The input is city_state

```{r}
prop.test(
  aggregate_df %>%  filter(city_state == "Baltimore_MD") %>%  pull(hom_unsolved),
  aggregate_df %>%  filter(city_state == "Baltimore_MD") %>%  pull(hom_total)) %>% 
  broom::tidy()
```

Try t0 iterate .........
Try to create a fourth column that has the data that is requested in homework assignment

```{r}
#conceptually, this is the framework:
#aggregate_df %>% 
#  mutate(
#    prop_tests = map( ....... )
#  )

results_df =
aggregate_df %>% 
  mutate(
    prop_tests = map2(.x = hom_unsolved, .y = hom_total, ~prop.test(x = .x, n = .y)),
    tidy_tests = map(.x = prop_tests, ~broom::tidy(.x))
  ) %>% 
  select(-prop_tests) %>% 
  unnest(tidy_tests) %>% 
  select(city_state, estimate, conf.low, conf.high)
```

```{r}
results_df %>%
  mutate(
    city_state = fct_reorder(city_state, estimate)  
  ) %>%
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) +
  theme(legend.position = "bottom", axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))


```



```{r, error = TRUE}
# this is an alternate way to approach
# city_prop_tst = function(df) {
  
#  n_unsolved ...
#  n_total ...

#  prop.test(........)  
  
#}

homicide_df =
  read_csv("homicide_data/homicide-data.csv") %>%
  mutate(
    city_state = str_c(city, state, sep = "_"),
    resolved = case_when(
      disposition == "Closed without arrest" ~ "unsolved",
      disposition == "Open/No arrest"        ~ "unsolved",
      disposition == "Closed by arrest"      ~ "solved"
    )
  ) %>%
  select(city_state, resolved) %>% 
  filter(city_state != "Tulsa_AL") %>% 
  nest(data = resolved)
```

## Problem 2 ideas ...

import one dataset

```{r}
data_1 = read_csv("lda_data/con_01.csv")
```

but the challenge is how to do it across the 10 subjects in the experimental group and 10 subjects in control group?

start with a dataframe with the names of all of your names

```{r}
#Live session lecture notes - please ignore
## if you can do this, then you would solve this part of the homework assignment
## then after this, you can do some mutate stuff
## probably need to pivot to made the dataset tidy
## could I get the actual dataframe I wanted to have to do some analysis or some plots
## this is a data organizational problem and data tidying problem
## in the end, everything will be in one dataframe
##list.files()
##list.files("lda_data")

#First, my function to read in all 20 .csv files
read_all_csvs = function(x) {
  
  data = read_csv(x)
 
  tibble(
    data = data
  )
  
}

#Next, my for loop
output = vector("list", length = 20)

for (i in 1:20) {
  
  output[[i]] = read_all_csvs(path_df$path[[i]])

}

path_df =
  tibble(
    path = list.files("lda_data"),
  ) %>% 
  mutate(
    path = str_c("lda_data/", path)
  ) %>% 
  mutate(
    data = map(path_df$path, read_all_csvs)
  )

study_data =
  path_df %>% 
  separate(path, into = c("prefix", "arm_id"), sep = 9) %>% 
  select(-prefix) %>% 
  separate(arm_id, into = c("arm_id", "csv"), sep = 6) %>%
  select(-csv) %>%
  unnest(data) %>% 
  mutate(
    week_1 = data$week_1,
    week_2 = data$week_2,
    week_3 = data$week_3,
    week_4 = data$week_4,
    week_5 = data$week_5,
    week_6 = data$week_6,
    week_7 = data$week_7,
    week_8 = data$week_8,
  ) %>% 
  select(arm_id, week_1:week_8) %>% 
  pivot_longer(
    week_1:week_8,
    names_to = "week",
    values_to = "observations"
  )
  
#read_csv(path_df$path[[1]])
#read_csv(path_df$path[[2]])


```

```{r}
#Spaghetti plot
```


# Problem 3 

```{r}
#This is a problem about simulations
#given: sample size = 30
#given: sd = 5
#change: means.  means of 1, 2, 3, 4, 5, 6
#for each mean, generate 5000 datasets
#not exporting means, sds
#export the results of the hypothesis test, whehter the mean is equal to zero.
#when mean = 0, reject or fail to reject the null hypthesis a certain percentage of times - see what happens as you move from the means.
#make two plots - estimated plot when true mean = zero
#and then filter, show only when p values<0.05 and then compute the mean, what would that mean look like.
# you are always testing that mean = 0

```

